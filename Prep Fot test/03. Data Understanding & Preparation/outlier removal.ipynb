{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b572dfb",
   "metadata": {},
   "source": [
    "### Interquartile Range (IQR) Approach\n",
    "Q1 (first quartile): Represents the value where 25% of the data falls below it and 75% falls above.\n",
    "Q2 (second quartile): This is the median of your data, the middle value when ordered.\n",
    "Q3 (third quartile): Represents the value where 75% of the data falls below it and 25% falls above.\n",
    "\n",
    "Interquartile Range (IQR):  This is simply the difference between the third quartile (Q3) and the first quartile (Q1). So,\n",
    "\n",
    "IQR=Q3−Q1.\n",
    "\n",
    "In layman's terms, the IQR tells us how spread out the data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18853da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, columns):\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    return df_clean\n",
    "\n",
    "numeric_columns = df.select_dtypes(include='number').columns.tolist()\n",
    "df_cleaned = remove_outliers_iqr(df, numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbea70",
   "metadata": {},
   "source": [
    "### The z-score Method\n",
    "In statistics, the z-score (also known as the standard score) tells you how many standard deviations a data point is from the mean of the distribution. The interpretati0n of the z-score is summarized in the following table:\n",
    "\n",
    "Z-score\tMeaning\n",
    "0\tData point is exactly at the mean\n",
    "+1\t1 standard deviation above the mean\n",
    "-1\t1 standard deviation below the mean\n",
    "> +3 or < -3\tPotential outlier (extreme deviation)\n",
    "z-Score and the Empirical Rule\n",
    "The Empirical Rule (also called the 68–95–99.7 Rule) for a normal distribution, which is the foundation for the z-score approach to outlier detection is illustrated by the following diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2c86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = df[numeric_columns].apply(zscore)\n",
    "df_cleaned = df[(abs(z_scores) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a173434",
   "metadata": {},
   "source": [
    "### Python Code - Isolation Forest\n",
    "For example, one can use the sklearn Isolation forest function to remove outliers as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af00ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "outliers = iso.fit_predict(df[numeric_columns])\n",
    "df_cleaned = df[outliers == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f9807",
   "metadata": {},
   "source": [
    "Consider keeping outliers if:\n",
    "\n",
    "- They represent real rare but valid cases (e.g., high-income clients).\n",
    "\n",
    "- The model is robust to them (e.g., tree-based methods).\n",
    "\n",
    "- Consider capping extreme values (i.e. using imputation) instead of removing the data points(a.k.a. winsorizing)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
