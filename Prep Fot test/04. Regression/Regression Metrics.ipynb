{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298ffd1f",
   "metadata": {},
   "source": [
    "# Choosing the Right Metric\n",
    "\n",
    "The best metric depends on your specific problem. Here are some considerations:\n",
    "\n",
    "- **MAE vs. MSE**: If large errors are particularly concerning, **MAE** might be better. For example, predicting house prices with a large error on a single expensive house would be worse than many smaller errors.\n",
    "- **MBE** tells you directional error — whether the model consistently overshoots or undershoots.\n",
    "- **MAE**, **MSE**, and **RMSE** reflect total error, combining bias and variance, but **RMSE** penalizes larger errors more.\n",
    "- **R2** doesn’t directly show error magnitude but reflects how well the model explains variation in the data (closer to 1 is better). While a high **R-squared** is desirable, it can be misleading if you have too many features (overfitting).\n",
    "\n",
    "### Metric Comparison Table\n",
    "\n",
    "| Metric                     | What It Measures                                                                 | Bias                      | Precision                        |\n",
    "|----------------------------|----------------------------------------------------------------------------------|---------------------------|----------------------------------|\n",
    "| **Mean Bias Deviation (MBE)** | Average of prediction errors (with sign), shows if predictions systematically over/underestimate | Yes. Directly measures bias | No. Does not assess spread      |\n",
    "| **Mean Absolute Error (MAE)**  | Average of absolute prediction errors; overall error magnitude                    | Yes. Captures bias indirectly | Yes. Captures overall error (spread) |\n",
    "| **Mean Squared Error (MSE)**   | Average of squared prediction errors. Penalizes larger errors more heavily         | Yes. Includes bias         | Yes. Sensitive to variance      |\n",
    "| **Root Mean Squared Error (RMSE)** | Square root of MSE. Interpretable in original units                               | Yes. Includes bias         | Yes. Sensitive to large deviations |\n",
    "| **R2 Score**                 | Proportion of variance explained by the model; compares model to naive mean prediction | Yes. Low if biased         | Yes. Low if imprecise           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d708ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Example predictions\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c35e7",
   "metadata": {},
   "source": [
    "2. Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb1143",
   "metadata": {},
   "source": [
    "3. Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937daad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab8787",
   "metadata": {},
   "source": [
    "4. R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b5b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2972453",
   "metadata": {},
   "source": [
    "## Summary of Metric Selection\n",
    "MAE is useful when you care about the total error and want a metric that doesn't overly penalize large errors.\n",
    "\n",
    "MSE and RMSE are better if larger errors are more costly in your problem, especially when squared terms penalize larger differences.\n",
    "\n",
    "R2 is helpful for understanding how well the model explains the variance in the data, but can be misleading with overfitting or too many features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
